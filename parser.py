"""The ShivyC parser. It's written entirely by hand because automatic parser
generators are no fun.

"""
import ast

from errors import CompilerError
import token_kinds

class Parser:
    """Provides the parser functionality to convert a list of tokens into an
    AST.

    Each internal function expect_* corresponds to a unique non-terminal symbol
    in the C grammar. It parses the given tokens beginning at the given index to
    try to match a grammar rule that generates the desired symbol. If a match is
    found, it returns a tuple (Node, length) where Node is an AST node for that
    match and length is the number of tokens consumed in that parse.  If a match
    is not found, returns (None, 0) and saves the potential error to the errors
    variable.

    errors (List[Tuple[CompilerError, int]]) - Stores a list of compiler errors
    for each time a potential parsing path failed, and the index at which that
    error occurred. If the parse is unsuccessful, we will raise the
    CompilerError that successfully parsed the most tokens.

    """
    def __init__(self):
        self.errors = []

    def parse(self, tokens):
        """Parse the provided list of tokens into an abstract syntax tree (AST)

        tokens (List[Token]) - A list of the tokens, as generated by the lexer
        returns (Node) - The root node of the generated AST"""

        node, length = self.expect_main(tokens, 0)
        if not node:
            # Parsing failed, so we return the error that was most successsful
            # at parsing.
            raise max(self.errors, key=lambda error: error[1])[0]

        # Ensure there's no tokens left at after the main function
        if tokens[length:]:
            raise self.make_error("unexpected token", length, tokens)
        return node

    def expect_main(self, tokens, index):
        """Ex: int main() { return 4; } """

        kinds_before = [token_kinds.int_kw, token_kinds.main,
                        token_kinds.open_paren, token_kinds.close_paren,
                        token_kinds.open_brack, token_kinds.return_kw]
        match_start = self.match_tokens(tokens[index:], kinds_before)
        if match_start:
            index += match_start
        else:
            err = "expected main function starting"
            return self.add_error(err, index, tokens)

        node, length = self.expect_expression(tokens, index)
        if node:
            index += length
        else:
            return (None, 0)

        kinds_after = [token_kinds.semicolon, token_kinds.close_brack]
        match_end = self.match_tokens(tokens[index:], kinds_after)
        if match_end:
            index += match_end
        else:
            err = "expected end of main function"
            return self.add_error(err, index, tokens)
        return (ast.MainNode(node), index)
        
    def expect_expression(self, tokens, index):
        """Ex: 5, 3, etc. Currently only supports single integers.

        We will soon remake this to be a shift-reduce parser."""

        if tokens[index].kind == token_kinds.number:
            return (ast.NumberNode(tokens[index]), 1)
        else:
            return self.add_error("expected number", index, tokens)

    #
    # Utility functions for the parser
    #
    
    def match_tokens(self, tokens, kinds_expected):
        """Checks if the provided tokens match the expected token kinds, in
        order. If the tokens all have the expected kind, returns the length of
        kinds_expected. Otherwise, returns 0.

        tokens (List[Token]) - A list of tokens
        expected (List[TokenKind, None]) - A list of token kinds to expect

        """
        if len(tokens) < len(kinds_expected): return False
        if all(kind == token.kind for kind, token
               in zip(kinds_expected, tokens)):
            return len(kinds_expected)
        else: return 0

    def add_error(self, message, index, tokens):
        """Generates a CompilerError and adds it to the list of errors at the
        given index. For convenience, also returns (None, 0)

        message (str) - the base message to put in the error
        tokens (List[Token]) - a list of tokens
        index (int) - the index of the offending token
        returns - (None, 0)

        """
        self.errors.append((self.make_error(message, index, tokens),
                           index))
        return (None, 0)
        
    def make_error(self, message, index, tokens):
        """Generate a CompilerError. 

        message (str) - the base message to put in the error
        tokens (List[Token]) - a list of tokens
        index (int) - the index of the offending token

        """
        if len(tokens) == 0:
            return CompilerError("{} at beginning of source".format(message))
        elif index < 0:
            return CompilerError(
                "{} before '{}'".format(message, tokens[0].content),
                tokens[0].file_name, tokens[0].line_num)
        elif index < len(tokens):
            return CompilerError(
                "{} at '{}'".format(message, tokens[index].content),
                tokens[index].file_name, tokens[index].line_num)
        else:  # index >= len(tokens)
            return CompilerError(
                "{} after '{}'".format(message, tokens[-1].content),
                tokens[-1].file_name, tokens[-1].line_num)

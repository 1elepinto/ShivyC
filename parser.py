"""The ShivyC parser. It's written entirely by hand because automatic parser
generators are no fun.

"""
import ast

from errors import CompilerError
import token_kinds

class Parser:
    """Provides the parser functionality to convert a list of tokens into an
    AST.

    Each internal function expect_* corresponds to a unique non-terminal symbol
    in the C grammar. It parses the given tokens to try to match a grammar rule
    that generates the desired symbol. If a match is found, it returns a tuple
    (Node, length) where Node is an AST node for that match and length is the
    number of tokens consumed in that parse.  If a match is not found, returns
    (None, 0) and saves the potential error to the errors variable. Also, each
    internal function accepts a index_start, used for error reporting to
    determine which parsing path was the most successful.

    errors (List[Tuple[CompilerError, int]]) - Stores a list of compiler errors
    for each time a potential parsing path failed, and the index at which that
    error occurred. If the parse is unsuccessful, we will raise the
    CompilerError that successfully parsed the most tokens.

    """
    def __init__(self):
        self.errors = []

    def parse(self, tokens):
        """Parse the provided list of tokens into an abstract syntax tree (AST)

        tokens (List[Token]) - A list of the tokens, as generated by the lexer
        returns (Node) - The root node of the generated AST"""

        node, length = self.expect_main(tokens[0:], 0)
        if not node:
            # Parsing failed, so we return the error that was most successsful
            # at parsing.
            raise max(self.errors, key=lambda error_info: error_info[1])[0]

        if tokens[length:]:
            raise CompilerError("unexpected token at '{}'".
                                format(tokens[length].content),
                                line_num = tokens[length].line_num,
                                file_name = tokens[0].file_name)

        return node

    def expect_main(self, tokens, index_start):
        """Ex: int main() { return 4; } """

        # The token kinds we expect to appear before the return value
        kinds_before = [token_kinds.int_kw, token_kinds.main,
                        token_kinds.open_paren, token_kinds.close_paren,
                        token_kinds.open_brack, token_kinds.return_kw]
        
        # The token kinds we expect to appear after the return value
        kinds_after = [token_kinds.semicolon, token_kinds.close_brack]
        
        kinds_match = (self.match_tokens(tokens, kinds_before) and
                       self.match_tokens(tokens[7:], kinds_after))

        if kinds_match:
            return (ast.MainNode(tokens[6]), 9)
        else:
            self.errors.append(
                (CompilerError("expected main function starting at '{}'".
                               format(tokens[0].content),
                               line_num = tokens[0].line_num,
                               file_name = tokens[0].file_name), index_start))
            return (None, 0)

    def match_tokens(self, tokens, kinds_expected):
        """Checks if the provided tokens match the expected token kinds, in
        order. If any of the tokens do not have the expected kind, returns
        False.

        tokens (List[Token]) - A list of tokens
        expected (List[TokenKind, None]) - A list of token kinds to expect

        """
        if len(tokens) < len(kinds_expected): return False
        return all(kind == token.kind
                   for kind, token in zip(kinds_expected, tokens))

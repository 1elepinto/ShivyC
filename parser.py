"""The ShivyC parser. It's written entirely by hand because automatic parser
generators are no fun.

"""
import ast

from errors import CompilerError
import token_kinds

class Parser:
    """Provides the parser functionality to convert a list of tokens into an
    AST.

    Each internal function expect_* corresponds to a unique non-terminal symbol
    in the C grammar. It parses the given tokens beginning at the given index to
    try to match a grammar rule that generates the desired symbol. If a match is
    found, it returns a tuple (Node, length) where Node is an AST node for that
    match and length is the number of tokens consumed in that parse.  If a match
    is not found, returns (None, 0) and saves the potential error to the errors
    variable.

    errors (List[Tuple[CompilerError, int]]) - Stores a list of compiler errors
    for each time a potential parsing path failed, and the index at which that
    error occurred. If the parse is unsuccessful, we will raise the
    CompilerError that successfully parsed the most tokens.

    """
    def __init__(self):
        self.errors = []

    def parse(self, tokens):
        """Parse the provided list of tokens into an abstract syntax tree (AST)

        tokens (List[Token]) - A list of the tokens, as generated by the lexer
        returns (Node) - The root node of the generated AST"""

        node, length = self.expect_main(tokens, 0)
        if not node:
            # Parsing failed, so we return the error that was most successsful
            # at parsing.
            raise max(self.errors, key=lambda error: error[1])[0]

        # Ensure there's no tokens left at after the main function
        if tokens[length:]:
            raise CompilerError("unexpected token at '{}'".
                                format(tokens[length].content),
                                line_num = tokens[length].line_num,
                                file_name = tokens[0].file_name)
        return node

    def expect_main(self, tokens, index):
        """Ex: int main() { return 4; } """

        kinds_before = [token_kinds.int_kw, token_kinds.main,
                        token_kinds.open_paren, token_kinds.close_paren,
                        token_kinds.open_brack, token_kinds.return_kw]
        match_start = self.match_tokens(tokens[index:], kinds_before)
        if match_start:
            index += match_start
        else:
            self.errors.append(
                (CompilerError("expected main function starting at '{}'"
                               .format(tokens[index].content),
                               line_num = tokens[index].line_num,
                               file_name = tokens[index].file_name),
                 index))
            return (None, 0)

        node, length = self.expect_expression(tokens, index)
        if node:
            index += length
        else:
            return (None, 0)

        kinds_after = [token_kinds.semicolon, token_kinds.close_brack]
        match_end = self.match_tokens(tokens[index:], kinds_after)
        if match_end:
            index += match_end
        else:
            self.errors.append(
                (CompilerError("expected end of main function starting at '{}'"
                               .format(tokens[index].content),
                               line_num = tokens[index].line_num,
                               file_name = tokens[index].file_name),
                 index))
            return (None, 0)
        return (ast.MainNode(node), index)
        
    def expect_expression(self, tokens, index):
        """Ex: 5, 3, etc. Currently only supports single integers.

        We will soon remake this to be a shift-reduce parser."""

        if tokens[index].kind == token_kinds.number:
            return (ast.NumberNode(tokens[index]), 1)
        else:
            self.errors.append(
                (CompilerError("expected number at '{}'"
                               .format(tokens[index].content),
                               line_num = tokens[index].line_num,
                               file_name = tokens[index].file_name),
                 index))
            return (None, 0)
        
    def match_tokens(self, tokens, kinds_expected):
        """Checks if the provided tokens match the expected token kinds, in
        order. If the tokens all have the expected kind, returns the length of
        kinds_expected. Otherwise, returns 0.

        tokens (List[Token]) - A list of tokens
        expected (List[TokenKind, None]) - A list of token kinds to expect

        """
        if len(tokens) < len(kinds_expected): return False
        if all(kind == token.kind for kind, token
               in zip(kinds_expected, tokens)):
            return len(kinds_expected)
        else: return 0
